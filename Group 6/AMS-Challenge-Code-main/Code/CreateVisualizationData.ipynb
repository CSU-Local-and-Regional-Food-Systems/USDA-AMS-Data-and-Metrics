{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3534f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt \n",
    "import geopandas as gpd\n",
    "import shapely.geometry\n",
    "from shapely.geometry import Point,MultiPolygon,Polygon\n",
    "\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33e59e",
   "metadata": {},
   "source": [
    "This is where the crs comes from: https://en.wikipedia.org/wiki/EPSG_Geodetic_Parameter_Dataset#:~:text=EPSG%3A4326%20%2D%20WGS%2084%2C,including%20Google%20Maps%20and%20OpenStreetMap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73082810",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# county visualization shape file\n",
    "\n",
    "gdf = gpd.read_file(\"cb_2018_us_county_500k/cb_2018_us_county_500k.shp\")\n",
    "#print(gdf.crs)\n",
    "gdf.to_crs('EPSG:4326') # converts to WSG84\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bd19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Land that people can hunt on \n",
    "\n",
    "huntingland = gpd.read_file(\"FWS_National_2022_-_2023_Hunt_Units/FWS_NWRS_HQ_PubHuntUnits.shp\")\n",
    "#print(huntingland['geometry'].crs) # this checks the gemoetry type\n",
    "huntingland = huntingland.to_crs('EPSG:4326') # converts to WSG84\n",
    "huntingland = huntingland[huntingland['Huntable']=='Yes']\n",
    "huntingland.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288e762",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First visualization\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# points_gdf.plot(column='org_type', categorical=True, ax=ax, cmap='Set1', \n",
    "#                 zorder=3, marker = '.', markersize = 1, edgecolor = 'none',\n",
    "#                legend=True, legend_kwds={'bbox_to_anchor':(.175,.35),'fontsize':4,'frameon':False,'markerscale':.5}\n",
    "#                ) # these are the points\n",
    "\n",
    "huntingland.plot(zorder = 2, ax = ax)\n",
    "\n",
    "gdf.plot(column = 'STATEFP' ,color = 'white' , edgecolor = 'black',ax = ax, zorder = 1, linewidth=.05) # this is the US map\n",
    "\n",
    "\n",
    "ax.axis('off')\n",
    "ax.set_title('Food Points in USA',fontsize=12)\n",
    "\n",
    "\n",
    "ax.set_xlim(-128, -60)\n",
    "#ax.get_ylim()[1] #- use this for the full y axis\n",
    "ax.set_ylim(22,50)\n",
    "#plt.savefig('US_MAP.jpg',dpi = 4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75a3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stored as  EPSG:4326\n",
    "water_gdf = gpd.read_file('Watershapefile/hydropol.shp')\n",
    "water_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060fc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for waterbody in water_gdf['DESCRIPT'].unique():\n",
    "#     print(waterbody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af574546",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_gdf['DESCRIPT'] = water_gdf['DESCRIPT'] .fillna('.')\n",
    "\n",
    "# codes for subsettting the data\n",
    "water_gdf['RIVER'] = water_gdf.apply(lambda x: 1 if x['DESCRIPT'][-5:]=='RIVER' else 0,axis = 1)\n",
    "water_gdf['OCEAN'] = water_gdf.apply(lambda x: 1 if x['DESCRIPT'][-5:]=='OCEAN' else 0,axis = 1)\n",
    "water_gdf['CHANNEL'] = water_gdf.apply(lambda x: 1 if x['DESCRIPT'][-7:]=='CHANNEL' else 0,axis = 1)\n",
    "water_gdf['SEA'] = water_gdf.apply(lambda x: 1 if x['DESCRIPT'][-3:]=='SEA' else 0,axis = 1)\n",
    "water_gdf['CREEK'] = water_gdf.apply(lambda x: 1 if x['DESCRIPT'][-4:]=='CREEK' else 0,axis = 1)\n",
    "\n",
    "\n",
    "\n",
    "# complex geometry tag\n",
    "water_gdf['COMPLEX'] = water_gdf[['RIVER','OCEAN','SEA','CHANNEL','CREEK']].sum(axis = 1) \n",
    "# convert to meters\n",
    "water_gdf = water_gdf.to_crs(\"EPSG:3857\") # Web mercator 84 ,like wsg 84 but the projection version\n",
    "# susbet the data\n",
    "# complex_water_gdf = water_gdf[water_gdf['COMPLEX']>0].copy()\n",
    "# simple_water_gdf = water_gdf[water_gdf['COMPLEX']==0].copy()\n",
    "# this subset the data into 500 meter increments instead of 40 feet\n",
    "# complex_water_gdf['geometry_simple'] = complex_water_gdf['geometry'].apply(lambda x:\n",
    "#                                                                            x.simplify(tolerance = 500, preserve_topology = False)\n",
    "#                                                                           ).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# simple_water_gdf['geometry_simple'] = simple_water_gdf['geometry'].centroid.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# water_gdf = pd.concat([simple_water_gdf,complex_water_gdf], axis = 0)\n",
    "# water_gdf = water_gdf.to_crs(\"EPSG:4326\") # back to lat and long\n",
    "\n",
    "\n",
    "\n",
    "water_gdf['geometry_simple'] = water_gdf['geometry'].apply(lambda x:\n",
    "                                                           x.simplify(tolerance = 1000, preserve_topology = False)\n",
    "                                                          ).to_crs(\"EPSG:4326\")\n",
    "                                                                           \n",
    "                                                                           \n",
    "water_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4362ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different game available on the land\n",
    "\n",
    "gametype = pd.read_csv('FWS_National_2022_-_2023_Hunt_Units.csv')\n",
    "gametype.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e5f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_game = ['Elk','Dark Geese', 'Dove', 'Light Geese',\n",
    "            'Quail', 'Squirrel','Rabbit & Hare','Coot', 'Duck',\n",
    "            'Feral Hog', 'Teal', 'White-Tailed Deer', 'Gallinule', 'Sea Duck',\n",
    "            'Turkey', 'Moorhen', 'Swan', 'Grouse', 'Pronghorn',\n",
    "            'Pheasant', 'Bear', 'Partridge', 'Sika Deer',\n",
    "            'Mule Deer', 'Sandhill Crane', 'Moose', 'Caribou', 'Javelina',\n",
    "            'Mountain Lion', 'Cormorant',\n",
    "            'Prairie Dog', 'Pigeon', 'Bighorn Sheep',\n",
    "            'Greater Prairie Chicken', 'Chukar', 'Alligator',\n",
    "            'Nilgai Antelope', 'Mountain Goat', 'Fallow Deer',\n",
    "            'Black-Tailed Deer', 'Russian Boar', 'Bison',\n",
    "            'Dall Sheep', 'Oryx', 'Muskox']\n",
    "keep_game = set(keep_game)\n",
    "gametype['usable_game'] = gametype.apply(lambda x: 1 if x['Species'] in keep_game else 0,axis = 1)\n",
    "gametype = gametype[['OBJECTID','usable_game']]\n",
    "gametype = gametype[gametype['usable_game']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94c726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gives us census tract data from the ACS\n",
    "\n",
    "census_tract = pd.read_csv('census_tract.csv', encoding=\"latin-1\")\n",
    "cols = list(census_tract.columns)\n",
    "keep_cols = []\n",
    "i = 0\n",
    "for col in cols:\n",
    "    if col[0:8] == 'Estimate':\n",
    "        keep_cols.append(col)\n",
    "    elif i == 0:\n",
    "        keep_cols.append(col)\n",
    "    elif i == 1:\n",
    "        keep_cols.append(col)\n",
    "    i+=1\n",
    "del cols\n",
    "census_tract = census_tract[keep_cols]\n",
    "#census_tract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1362327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the data I want to use\n",
    "data_list =['Geography',\n",
    "            'Geographic Area Name',\n",
    "            'Estimate!!Total!!Total population',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!White',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!Black or African American',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!American Indian and Alaska Native',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!Asian',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!Native Hawaiian and Other Pacific Islander',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!One race!!Some other race',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!Two or more races',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!Hispanic or Latino origin (of any race)',\n",
    "            'Estimate!!Total!!Total population!!RACE AND HISPANIC OR LATINO ORIGIN!!White alone, not Hispanic or Latino',\n",
    "            'Estimate!!Total!!POVERTY STATUS IN THE PAST 12 MONTHS!!Population for whom poverty status is determined',\n",
    "            'Estimate!!Total!!POVERTY STATUS IN THE PAST 12 MONTHS!!Population for whom poverty status is determined!!Below 100 percent of the poverty level',\n",
    "            'Estimate!!Total!!POVERTY STATUS IN THE PAST 12 MONTHS!!Population for whom poverty status is determined!!100 to 149 percent of the poverty level',\n",
    "            'Estimate!!Total!!POVERTY STATUS IN THE PAST 12 MONTHS!!Population for whom poverty status is determined!!At or above 150 percent of the poverty level']\n",
    "\n",
    "\n",
    "col_list = ['Geography','Geographic Area Name', 'population','White','Black',\n",
    "            'Native American','Asian','Hawaiian Pacific Islander', 'Other Race',\n",
    "            'Two or More','Hispanic','White not Hispanic','povertystatus_denom','below_poverty', '100-% poverty',\n",
    "            '150-% poverty', '150+% poverty']\n",
    "\n",
    "conversion_dict = dict(zip(data_list, col_list))\n",
    "census_tract = census_tract[data_list]\n",
    "census_tract = census_tract.rename(mapper = conversion_dict, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e4a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am doing a very evil thing here \n",
    "def newstring(string):\n",
    "    return(string[9:])\n",
    "census_tract['GEO_ID'] = census_tract['Geography'].apply(lambda x: newstring(x))\n",
    "def newstring(string):\n",
    "    return(string[0:2])\n",
    "FIPS = census_tract['GEO_ID'].apply(lambda x: newstring(x))\n",
    "FIPS = FIPS.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "census_tract.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64180ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" this is how I construct the wgts between 0 and 1, it depends evenly '\n",
    "    on the percent black native hawaiian other t and belowe 100% of the poverty line\"\"\"\n",
    "\n",
    "names = ['Black','Native American','Hawaiian Pacific Islander',\n",
    "         'Other Race','Two or More',\"Hispanic\",'below_poverty']\n",
    "\n",
    "census_tract[names] = census_tract[names].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "census_tract['wgt'] = census_tract[names].sum(axis = 1)\n",
    "census_tract['county_id'] = census_tract['GEO_ID'].apply(lambda x: x[0:5])\n",
    "census_county = census_tract.groupby('county_id').sum().reset_index()\n",
    "census_county = census_county[['wgt','county_id']].rename({'wgt':'wgt_sum'},axis = 1)\n",
    "census_tract = census_tract.merge(census_county, on = 'county_id',how = 'left')\n",
    "census_tract['wgt'] = census_tract['wgt']/census_tract['wgt_sum']\n",
    "\n",
    "right_df = census_tract[['GEO_ID','county_id','wgt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727c5a73",
   "metadata": {},
   "source": [
    "Our center is the mean lat and longitude of all available points:\n",
    "\n",
    "- share by race that is food insecure white black hispanic and other\n",
    "- other is pi and native american\n",
    "\n",
    "- 150\\% of federal poverty line\n",
    "- Percent of the county's population that is in the cnesus tract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171bbf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how I get the shape files for census tract by county\n",
    "\n",
    "censustract_gdflist = []\n",
    "for fip in FIPS:\n",
    "    \n",
    "    url = 'Census Tract Shape Files/tl_2020_'+fip+'_tract/tl_2020_'+fip+'_tract.shp'\n",
    "\n",
    "    ctract = gpd.read_file(url)\n",
    "    ctract = ctract.to_crs(\"EPSG:3857\") # Web mercator 84 like wsg 84 but the projection version\n",
    "    ctract['centroid'] = ctract['geometry'].centroid\n",
    "    ctract['lon'] = ctract.centroid.apply(lambda p: p.x)\n",
    "    ctract['lat'] = ctract.centroid.apply(lambda p: p.y)\n",
    "    censustract_gdflist.append(ctract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2da80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the centroid of huntable land\n",
    "\n",
    "huntingland_centroid = huntingland.to_crs(\"EPSG:3857\") # Web mercator 84 like wsg 84 but the projection version\n",
    "huntingland_centroid['centroid'] = huntingland_centroid['geometry'].centroid\n",
    "huntingland_centroid['lon'] = huntingland_centroid.centroid.apply(lambda p: p.x)\n",
    "huntingland_centroid['lat'] = huntingland_centroid.centroid.apply(lambda p: p.y)\n",
    "\n",
    "huntingland_centroid = huntingland_centroid[['OBJECTID','lon','lat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e02808",
   "metadata": {},
   "outputs": [],
   "source": [
    "huntingland_centroid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e623b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is the weighted centroid\n",
    "synth_family = pd.DataFrame(columns = ['county_id','lon_wgt','lat_wgt'])\n",
    "for geodf in censustract_gdflist:\n",
    "    geodf = geodf.merge(right_df, left_on = 'GEOID',right_on = 'GEO_ID')\n",
    "    geodf[['lon_wgt','lat_wgt']] = geodf[['lon','lat']].multiply(geodf['wgt'],axis=0)\n",
    "    geodf = geodf[['lon_wgt','lat_wgt','county_id']].groupby('county_id').sum().reset_index()\n",
    "    synth_family = pd.concat([synth_family,geodf])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I lose some territories\n",
    "synth_family = synth_family.dropna(axis = 0)\n",
    "synth_family_gdf = gpd.GeoDataFrame(synth_family,\n",
    "                                            geometry=gpd.points_from_xy(synth_family.lon_wgt, synth_family.lat_wgt),\n",
    "                                            crs=\"EPSG:3857\")\n",
    "synth_family_gdf = synth_family_gdf.to_crs(\"EPSG:4326\") # to degrees\n",
    "#synth_family= synth_family.to_crs(\"EPSG:4269\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f682b44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csa_names = ['listing_id','location_x','location_y',\n",
    "             'acceptedpayment','FNAP','products','product_fruit',\n",
    "             'product_vegetables','product_fishseafood',\n",
    "             'product_poultryfowl_otherdesc','product_poultryfowl','product_redmeat']\n",
    "\n",
    "farmersmarket_names = ['listing_id','location_x','location_y','acceptedpayment','FNAP']\n",
    "\n",
    "foodhubs_names = ['listing_id','location_x','location_y','acceptedpayment','FNAP','products']\n",
    "\n",
    "\n",
    "\n",
    "farm_mark = pd.read_excel('PointData/FarmersMarket.xlsx')\n",
    "farm_mark = farm_mark[farmersmarket_names]\n",
    "farm_mark_gdf = gpd.GeoDataFrame(farm_mark, \n",
    "                                 geometry=gpd.points_from_xy(farm_mark.location_x, farm_mark.location_y),\n",
    "                                 crs=\"EPSG:4269\") # not sure but they are long and lat\n",
    "farm_mark_gdf = farm_mark_gdf[farm_mark_gdf['geometry'].is_empty != True]\n",
    "\n",
    "csa = pd.read_excel('PointData/CSA.xlsx')\n",
    "csa = csa[csa_names]\n",
    "csa_gdf = gpd.GeoDataFrame(csa,\n",
    "                           geometry=gpd.points_from_xy(csa.location_x, csa.location_y),\n",
    "                           crs=\"EPSG:4269\")\n",
    "csa_gdf = csa_gdf[csa_gdf['geometry'].is_empty != True]\n",
    "\n",
    "\n",
    "foodhub = pd.read_excel('PointData/Foodhub.xlsx')\n",
    "foodhub = foodhub[foodhubs_names]\n",
    "foodhub_gdf = gpd.GeoDataFrame(foodhub,\n",
    "                               geometry=gpd.points_from_xy(foodhub.location_x, foodhub.location_y),\n",
    "                               crs=\"EPSG:4269\")\n",
    "foodhub_gdf = foodhub_gdf[foodhub_gdf['geometry'].is_empty != True]\n",
    "\n",
    "\n",
    "del csa,foodhub,farm_mark\n",
    "\n",
    "farm_mark_gdf = farm_mark_gdf.to_crs(\"EPSG:4326\") # to degrees\n",
    "foodhub_gdf = foodhub_gdf.to_crs(\"EPSG:4326\")\n",
    "csa_gdf = csa_gdf.to_crs(\"EPSG:4326\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568505d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "huntingland_centroid_df=pd.DataFrame(huntingland_centroid)\n",
    "huntingland_centroid_gdf=gpd.GeoDataFrame(huntingland_centroid_df, \n",
    "                                          geometry = gpd.points_from_xy(huntingland_centroid_df.lon, huntingland_centroid_df.lat),\n",
    "                                          crs = 'EPSG:3857')\n",
    "\n",
    "huntingland_centroid_gdf = huntingland_centroid_gdf.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ee1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vegetables\n",
    "fruit_veglist = ['product_vegetables','product_fruit']\n",
    "for plant in fruit_veglist:\n",
    "    csa_gdf[plant] = csa_gdf[plant].isnull()\n",
    "    csa_gdf[plant] = csa_gdf.apply(lambda x: 1 if x[plant] == False else 0, axis = 1)\n",
    "\n",
    "#Meatlist\n",
    "meatlist = ['product_fishseafood','product_poultryfowl_otherdesc','product_poultryfowl','product_redmeat']\n",
    "for meat in meatlist:\n",
    "    csa_gdf[meat] = csa_gdf[meat].isnull()\n",
    "    csa_gdf[meat] = csa_gdf.apply(lambda x: 1 if x[meat] == False else 0, axis = 1)\n",
    "\n",
    "csa_gdf['plant'] = csa_gdf[fruit_veglist].sum(axis=1)\n",
    "csa_gdf['meat'] = csa_gdf[meatlist].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc13b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for meat and plant \n",
    "\n",
    "cols = ['listing_id','geometry']\n",
    "\n",
    "meat_gdf = csa_gdf[csa_gdf['meat']>=1]\n",
    "plant_gdf = csa_gdf[csa_gdf['plant']>=1]\n",
    "\n",
    "meat_gdf = pd.concat([meat_gdf[cols],farm_mark_gdf[cols]],axis = 0)\n",
    "plant_gdf = pd.concat([plant_gdf[cols],farm_mark_gdf[cols]],axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5ed9eb",
   "metadata": {},
   "source": [
    "divide up point data into meat veg and foodhub if wic and/or snap, min distance by each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e15e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_family_df = pd.DataFrame(synth_family_gdf)\n",
    "\n",
    "synth_family_df['county_id'] = pd.to_numeric(synth_family_df['county_id'])\n",
    "synth_family_df = synth_family_df[synth_family_df['county_id']<72000]\n",
    "\n",
    "meat_df = pd.DataFrame(meat_gdf)\n",
    "foodhub_df = pd.DataFrame(foodhub_gdf)\n",
    "plant_df = pd.DataFrame(plant_gdf)\n",
    "huntingland_centroid_df = pd.DataFrame(huntingland_centroid_gdf)\n",
    "huntingland_centroid_df = huntingland_centroid_df[['OBJECTID','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d4ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_family_df.to_excel('synthetic_family.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152432f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "huntingland_centroid_df = huntingland_centroid_df.merge(gametype, \n",
    "                                                        how = 'left', on = 'OBJECTID',indicator = True)\n",
    "huntingland_centroid_df =  huntingland_centroid_df[huntingland_centroid_df['_merge']=='both']\n",
    "huntingland_centroid_df =  huntingland_centroid_df[['OBJECTID','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8119dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate distance using the Haversine Formula\n",
    "def rad(deg):\n",
    "    radians = deg * math.pi/180\n",
    "    return(radians)\n",
    "\n",
    "def haversine(coord1,coord2):\n",
    "    \n",
    "    lon1 = rad(coord1.x)\n",
    "    lat1 = rad(coord1.y)\n",
    "    lon2 = rad(coord2.x)\n",
    "    lat2 = rad(coord2.y)\n",
    "\n",
    "    r = 6371000.7900 \n",
    "    \n",
    "    delta_phi = lat2 - lat1\n",
    "    delta_lambda = lon2 - lon1\n",
    "\n",
    "    a = math.sin(delta_phi / 2.0) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    meters = r * c  # output distance in meters\n",
    "    miles = meters * 0.0006213711922 # output distance in miles\n",
    "    \n",
    "    miles = round(miles, 2)\n",
    "\n",
    "\n",
    "    return(miles)\n",
    "\n",
    "def haversine_water(coord1,coord2):\n",
    "    \n",
    "    lon1 = rad(coord1.x)\n",
    "    lat1 = rad(coord1.y)\n",
    "    lon2 = rad(coord2[0])\n",
    "    lat2 = rad(coord2[1])\n",
    "\n",
    "    r = 6371000.7900 \n",
    "    \n",
    "    delta_phi = lat2 - lat1\n",
    "    delta_lambda = lon2 - lon1\n",
    "\n",
    "    a = math.sin(delta_phi / 2.0) ** 2 + math.cos(lat1) * math.cos(lat2) * math.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    meters = r * c  # output distance in meters\n",
    "    miles = meters * 0.0006213711922 # output distance in miles\n",
    "    \n",
    "    miles = round(miles, 2)\n",
    "\n",
    "\n",
    "    return(miles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bd1727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_distance(df_list,synth_family_df,name_list):\n",
    "    output_df = pd.DataFrame(synth_family_df['county_id'])\n",
    "    i = 0\n",
    "    for df in df_list:\n",
    "        cross_prod = synth_family_df.merge(df, how = 'cross')\n",
    "        cross_prod['distance'] = cross_prod.apply(lambda x: haversine(x['geometry_x'], x['geometry_y']), axis = 1)\n",
    "        \n",
    "        temp_df = cross_prod.groupby('county_id').min('distance').reset_index()\n",
    "        temp_df = temp_df[['county_id','distance']]\n",
    "        name = 'distance_'+name_list[i]\n",
    "        temp_df = temp_df.rename({'distance':name},axis = 1)\n",
    "        i+=1\n",
    "        output_df = output_df.merge(temp_df, how = 'left', on = 'county_id')\n",
    "        \n",
    "    return(output_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #synth_family\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "synth_family_gdf.plot( ax=ax, zorder=2, marker = '.', markersize = .1,edgecolor = 'none') # these are the points\n",
    "\n",
    "gdf.plot(column = 'STATEFP' ,color = 'white' , edgecolor = 'black',ax = ax, zorder = 1, linewidth=.05) # this is the US map\n",
    "\n",
    "huntingland.plot(zorder = 3, ax = ax, markersize = .1, color = 'yellow')\n",
    "meat_gdf.plot(zorder = 4, ax = ax, markersize = .1,edgecolor = 'none', color = 'red')\n",
    "foodhub_gdf.plot(zorder = 5, ax = ax, markersize = .1,edgecolor = 'none', color = 'brown')\n",
    "plant_gdf.plot(zorder = 6, ax = ax, markersize = .1,edgecolor = 'none', color = 'green')\n",
    "water_gdf.plot(zorder = 7, ax = ax, markersize = .1,edgecolor = 'none', color = 'blue')\n",
    "\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "ax.set_xlim(-128, -60)\n",
    "#ax.get_ylim()[1] - use this for the full y axis\n",
    "ax.set_ylim(22,50)\n",
    "#plt.savefig('synthetic_hh.jpg',dpi = 4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5524601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# water dataframe substted\n",
    "\n",
    "water_gdf['unit_id'] = range(0,len(water_gdf))\n",
    "water_gdf = water_gdf[['unit_id','centroid','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc03d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_boundary_points(geometry):\n",
    "    boundary_points = []\n",
    "    if isinstance(geometry, Polygon) == True:\n",
    "        boundary_points = list(geometry.exterior.coords)\n",
    "        \n",
    "    elif isinstance(geometry, MultiPolygon) == True:\n",
    "        for geom in geometry.geoms:\n",
    "            boundary_points.extend(list(geom.exterior.coords))\n",
    "\n",
    "    return(boundary_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9c0f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how I extract the boundayr points\n",
    "\n",
    "master_coord = []\n",
    "for coordlist in list(water_gdf['geometry_simple'].apply(lambda x: extract_boundary_points(x))):\n",
    "    master_coord.extend(coordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7ed031",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "master_coord_df = pd.DataFrame(master_coord, columns = [' long','lat'])\n",
    "master_coord_df['geometry_2'] = master_coord\n",
    "master_coord_df = master_coord_df['geometry_2']\n",
    "master_coord_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab96d4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_family_water_df = synth_family_df[['geometry','county_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aae23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_compare_df = synth_family_water_df.merge(master_coord_df, how = 'cross')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6920514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_compare_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b56544",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_compare_df['distance'] = water_compare_df.apply(lambda x: haversine_water(x['geometry'],x['geometry_2']),\n",
    "                                                      axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf9b89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_min_diff = water_compare_df.groupby('county_id').min('distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eed30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_min_diff.to_csv('results_waterdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e42a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_point_list = list(synth_family_df['geometry'])\n",
    "county_name_list = list(synth_family_df['county_id'])\n",
    "\n",
    "file = open('distances.txt','w')\n",
    "county_min_list = []\n",
    "i=0 # county indexer\n",
    "for county in county_point_list:\n",
    "    min_val = None # prime the minimum value\n",
    "    for geometry in master_coord: # looking through all lakes, geometry is a coordninate\n",
    "        val = haversine_water(county,geometry) # this is the value we compare\n",
    "        if min_val == None: # first iteration check\n",
    "            min_val = val # assign value\n",
    "        elif min_val > val: # otherwise if val ie less thatn min val\n",
    "            min_val = val # assign value\n",
    "            \n",
    "    if i % 200 == 0:\n",
    "        print(i)\n",
    "    county_min_list.append((county_name_list[i],min_val)) # append the minimum\n",
    "    file.write(str(county_name_list[i])+','+str(min_val)+\"\\n\")\n",
    "    i+=1\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761fc05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df_list = [meat_df, plant_df, foodhub_df,huntingland_centroid_df]\n",
    "name_list = ['meat','plant','foodhub','hunting']\n",
    "\n",
    "location_df = min_distance(df_list,synth_family_df,name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fe180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba930b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df['lon'] = location_df['geometry'].apply(lambda x: x.coords.x,)\n",
    "location_df.to_excel('county_distance.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678aefbc",
   "metadata": {},
   "source": [
    "PCA component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edaaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "county_food_sec_df = pd.read_csv('variables_for_index_clean.csv')\n",
    "county_food_sec_df = pd.pivot(county_food_sec_df, index='fips', columns='variable_name', values='value').reset_index()\n",
    "county_food_sec_df= county_food_sec_df.dropna(axis = 0)\n",
    "county_food_sec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878c0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df['county_id'] = pd.to_numeric(location_df['county_id'])\n",
    "master_df = location_df.merge(county_food_sec_df,how = 'left', left_on ='county_id',right_on = 'fips' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e21926",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.to_excel('master_file.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c57b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stuff in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab4c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.read_excel('master_file.xlsx')\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14e4bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf['county_id'] = gdf.apply(lambda x: str(x['STATEFP'])+str(x['COUNTYFP']),axis = 1)\n",
    "gdf['county_id'] = pd.to_numeric(gdf['geoid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3fc934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "food_sec_gdf= gdf.merge(index, how = 'left', on = 'county_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a6773a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #synth_family\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "food_sec_gdf.plot(column = 'index' ,ax = ax,cmap = 'seismic',\n",
    "                  zorder = 1, linewidth=.05,\n",
    "                  legend = True ) # this is the US map\n",
    "\n",
    "# huntingland.plot(zorder = 3, ax = ax, markersize = .1)\n",
    "# meat_gdf.plot(zorder = 4, ax = ax, markersize = .1)\n",
    "# foodhub_gdf.plot(zorder = 5, ax = ax, markersize = .1)\n",
    "# plant_gdf.plot(zorder = 6, ax = ax, markersize = .1)\n",
    "\n",
    "\n",
    "\n",
    "ax.axis('off')\n",
    "\n",
    "ax.set_xlim(-128, -60)\n",
    "#ax.get_ylim()[1] - use this for the full y axis\n",
    "ax.set_ylim(22,50)\n",
    "plt.savefig('INDEX_MAP.jpg',dpi = 4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417de43d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
